{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":72489,"databundleVersionId":8096274,"sourceType":"competition"}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/liaoguoying/unethology-predict-age-with-unet?scriptVersionId=172162636\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"!pip install pytorch-lightning qqq \n!pip install segmentation-models-pytorch qqq\nimport pandas as pd\nimport numpy as np\nfrom torch.utils.data import DataLoader, Dataset, random_split\nimport torch\nimport torch.nn as nn\nimport pytorch_lightning as pl\nimport segmentation_models_pytorch as smp\nfrom pytorch_lightning.loggers import WandbLogger\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"987c4cb8-9035-497f-b208-cc779b72a2dd","_cell_guid":"699951bf-ecbb-443e-9c82-3f7ea79b941e","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Load the training dataset\ntrain_data_path = \"/kaggle/input/playground-series-s4e4/train.csv\"\ntrain_data = pd.read_csv(train_data_path)\n\n# Display the first 5 rows of the training dataset\nprint(train_data.head())\nprint('#################################################################')\n\n# Get basic information about the dataset, including data types and non-null values for each column\nprint(train_data.info())\nprint('#################################################################')\n\n# Perform exploratory data analysis to understand the distribution of the data\nprint(train_data.describe())\nprint('#################################################################')\n","metadata":{"_uuid":"fbc863d9-8c52-4df9-8981-4393fb32aea3","_cell_guid":"9cfadee4-8c6f-4910-a0f9-16ac83c2189a","collapsed":false,"execution":{"iopub.status.busy":"2024-04-14T15:51:18.565551Z","iopub.execute_input":"2024-04-14T15:51:18.566173Z","iopub.status.idle":"2024-04-14T15:51:18.925017Z","shell.execute_reply.started":"2024-04-14T15:51:18.566117Z","shell.execute_reply":"2024-04-14T15:51:18.92372Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the data\ndata = pd.read_csv('/kaggle/input/playground-series-s4e4/train.csv')\n\n# Display basic information about the data\nprint(\"Initial Data Information:\")\nprint(data.info())\nprint('#################################################################')\n\n# 1. Check and handle records with height 0\nzero_height = data[data['Height'] == 0]\nprint(\"Number of records with height 0:\", zero_height.shape[0])\nprint('#################################################################')\n\n# You can choose to delete these rows or replace them with mean/median\ndata = data[data['Height'] > 0]  # Delete these rows\n# or\n# median_height = data['Height'].median()\n# data.loc[data['Height'] == 0, 'Height'] = median_height  # Replace with median\n\n# 2. Encode categorical variables and ensure they are floating-point\ndata['Sex'] = data['Sex'].map({'M': 0.0, 'F': 1.0, 'I': 2.0})  # Label encoding to float\n# Convert data type to float\ndata['Sex'] = data['Sex'].astype(float)\n\n# 3. Data normalization\nfrom sklearn.preprocessing import StandardScaler\n\n# Define columns to be normalized\nfeatures_to_scale = ['Sex', 'Length', 'Diameter', 'Height', 'Whole weight', 'Whole weight.1', 'Whole weight.2', 'Shell weight']\n\n# Initialize the scaler\nscaler = StandardScaler()\n\n# Normalize these columns\ndata[features_to_scale] = scaler.fit_transform(data[features_to_scale])\n\n# Display a sample of the normalized data\nprint(\"Sample of normalized data:\")\nprint(data[features_to_scale].head())\n\n# Save the cleaned data to the specified folder\ndata.to_csv('/kaggle/working/cleaned_data.csv', index=False)\nprint(\"Data cleaning completed and saved to '/kaggle/working/cleaned_data.csv'.\")\n\nprint(\"Data cleaning completed and saved to cleaned_data.csv\")\nprint('#################################################################')\n\n# Display basic information about the cleaned data\nprint(\"Cleaned Data Information:\")\nprint(data.info())\nprint('#################################################################')\n\n# Display the first 5 rows of the cleaned dataset\nprint(\"First 5 rows of cleaned dataset:\")\nprint(data.head())\nprint('#################################################################')\n","metadata":{"_uuid":"79525daa-444d-4fc5-a023-7146f8a65d9b","_cell_guid":"9eaee443-38bd-4140-b735-7e29203d6f6c","collapsed":false,"execution":{"iopub.status.busy":"2024-04-14T15:52:07.769926Z","iopub.execute_input":"2024-04-14T15:52:07.770432Z","iopub.status.idle":"2024-04-14T15:52:09.848933Z","shell.execute_reply.started":"2024-04-14T15:52:07.770387Z","shell.execute_reply":"2024-04-14T15:52:09.847513Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display basic information about the data\nprint(data.info())  # Now we have reduced outliers and normalized the data\nprint('#################################################################')\n\n# Display the first 5 rows of the cleaned dataset\nprint(\"First 5 rows of cleaned dataset:\")\nprint(data.head())\nprint('#################################################################')\n","metadata":{"_uuid":"b1657efe-413b-4d7a-8082-43c88b1e10f5","_cell_guid":"31849d58-a2bc-419e-8df3-99fd56e86a58","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-14T15:53:55.02757Z","iopub.execute_input":"2024-04-14T15:53:55.028122Z","iopub.status.idle":"2024-04-14T15:53:55.052483Z","shell.execute_reply.started":"2024-04-14T15:53:55.028082Z","shell.execute_reply":"2024-04-14T15:53:55.05101Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 90609 entries, 0 to 90614\nData columns (total 10 columns):\n #   Column          Non-Null Count  Dtype  \n---  ------          --------------  -----  \n 0   id              90609 non-null  int64  \n 1   Sex             90609 non-null  float64\n 2   Length          90609 non-null  float64\n 3   Diameter        90609 non-null  float64\n 4   Height          90609 non-null  float64\n 5   Whole weight    90609 non-null  float64\n 6   Whole weight.1  90609 non-null  float64\n 7   Whole weight.2  90609 non-null  float64\n 8   Shell weight    90609 non-null  float64\n 9   Rings           90609 non-null  int64  \ndtypes: float64(8), int64(2)\nmemory usage: 7.6 MB\nNone\n#################################################################\n   id Sex  Length  Diameter  Height  Whole weight  Whole weight.1  \\\n0   0   F   0.550     0.430   0.150        0.7715          0.3285   \n1   1   F   0.630     0.490   0.145        1.1300          0.4580   \n2   2   I   0.160     0.110   0.025        0.0210          0.0055   \n3   3   M   0.595     0.475   0.150        0.9145          0.3755   \n4   4   I   0.555     0.425   0.130        0.7820          0.3695   \n\n   Whole weight.2  Shell weight  Rings  \n0          0.1465        0.2400     11  \n1          0.2765        0.3200     11  \n2          0.0030        0.0050      6  \n3          0.2055        0.2500     10  \n4          0.1600        0.1975      9  \n#################################################################\n","output_type":"stream"}]},{"cell_type":"code","source":"class AbaloneDataset(Dataset):\n    \"\"\"\n    A custom dataset class for the Abalone dataset.\n    \"\"\"\n\n    def __init__(self, dataframe):\n        \"\"\"\n        Initialize the dataset with the provided DataFrame.\n\n        Args:\n            dataframe (pandas.DataFrame): The input DataFrame containing the Abalone data.\n        \"\"\"\n        self.dataframe = dataframe\n\n    def __len__(self):\n        \"\"\"\n        Return the length of the dataset (number of samples).\n\n        Returns:\n            int: The length of the dataset.\n        \"\"\"\n        return len(self.dataframe)\n\n    def expand_and_fill(self, data):\n        \"\"\"\n        Expand and fill the input data into a 32x32 single-channel matrix.\n\n        Args:\n            data (torch.Tensor): The input data with shape [feature_size], where feature_size=8.\n\n        Returns:\n            torch.Tensor: The expanded and filled data with shape [32, 32].\n        \"\"\"\n        # Initialize a 32x32 output matrix\n        output = torch.zeros((32, 32))\n\n        # Fill each 4 rows with one feature\n        for i in range(8):\n            output[i * 4:(i + 1) * 4, :] = data[i]\n\n        return output.unsqueeze(0)\n\n    def __getitem__(self, idx):\n        \"\"\"\n        Get a single data sample and its corresponding target value.\n\n        Args:\n            idx (int): The index of the sample in the dataset.\n\n        Returns:\n            tuple: A tuple containing the data (torch.Tensor) and target (torch.Tensor).\n        \"\"\"\n        # Extract all features except 'id' and 'Rings'\n        data = torch.tensor(\n            self.dataframe.iloc[idx][1:-1].values.astype(np.float32)\n        )  # Exclude id and Rings\n\n        # Expand and fill the data into a 32x32 matrix\n        data = self.expand_and_fill(data)\n\n        # Get the target value (Rings)\n        target = torch.tensor(self.dataframe.iloc[idx][-1], dtype=torch.float32)\n\n        return data, target\n\n\n# Load the data\ndataframe = pd.read_csv('/kaggle/working/cleaned_data.csv')\n\n# Create the dataset\ndataset = AbaloneDataset(dataframe)\n\n# Determine the size of the training and validation sets\nval_size = int(0.2 * len(dataset))  # Validation set size is 20% of the dataset\ntrain_size = len(dataset) - val_size  # Training set size is the remaining portion\n\n# Randomly split the dataset\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)\n\n# Check the output of the data loaders\nfor data, target in train_loader:\n    print(\"Train batch - Data shape:\", data.shape, \"; Target shape:\", target.shape)\n    break\n\nfor data, target in val_loader:\n    print(\"Validation batch - Data shape:\", data.shape, \"; Target shape:\", target.shape)\n    break\n","metadata":{"_uuid":"3c1c3d20-5321-4a11-a21e-422d0a040b11","_cell_guid":"445d5fbe-a27c-45c0-a058-aee40609704f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-14T16:04:59.979298Z","iopub.execute_input":"2024-04-14T16:04:59.979791Z","iopub.status.idle":"2024-04-14T16:05:01.086727Z","shell.execute_reply.started":"2024-04-14T16:04:59.979752Z","shell.execute_reply":"2024-04-14T16:05:01.085433Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/tmp/ipykernel_33/2664565292.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  target = torch.tensor(self.dataframe.iloc[idx][-1], dtype=torch.float32)  # Rings浣涓虹\n/tmp/ipykernel_33/2664565292.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  target = torch.tensor(self.dataframe.iloc[idx][-1], dtype=torch.float32)  # Rings浣涓虹\n/tmp/ipykernel_33/2664565292.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  target = torch.tensor(self.dataframe.iloc[idx][-1], dtype=torch.float32)  # Rings浣涓虹\n/tmp/ipykernel_33/2664565292.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  target = torch.tensor(self.dataframe.iloc[idx][-1], dtype=torch.float32)  # Rings浣涓虹\n","output_type":"stream"},{"name":"stdout","text":"Train batch - Data shape: torch.Size([64, 8, 32, 32]) ; Target shape: torch.Size([64])\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/2664565292.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  target = torch.tensor(self.dataframe.iloc[idx][-1], dtype=torch.float32)  # Rings浣涓虹\n/tmp/ipykernel_33/2664565292.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  target = torch.tensor(self.dataframe.iloc[idx][-1], dtype=torch.float32)  # Rings浣涓虹\n/tmp/ipykernel_33/2664565292.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  target = torch.tensor(self.dataframe.iloc[idx][-1], dtype=torch.float32)  # Rings浣涓虹\n/tmp/ipykernel_33/2664565292.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  target = torch.tensor(self.dataframe.iloc[idx][-1], dtype=torch.float32)  # Rings浣涓虹\n","output_type":"stream"},{"name":"stdout","text":"Validation batch - Data shape: torch.Size([64, 8, 32, 32]) ; Target shape: torch.Size([64])\n","output_type":"stream"}]},{"cell_type":"code","source":"# Get the first batch of data from the train_loader\ndata_iter = iter(train_loader)\ndata_batch = next(data_iter)\n\n# Unpack the batch data\ninputs, targets = data_batch\n\n# Print the shapes and some data points to confirm correct data loading\nprint(\"Input batch shape:\", inputs.shape)\nprint(\"Target batch shape:\", targets.shape)\nprint(\"First few inputs:\", inputs[0])\nprint(\"First few targets:\", targets[0])\n\n# Select a sample input to visualize\ndata_to_show = inputs[0]\n\n# Set up matplotlib plot\nfig, axes = plt.subplots(nrows=1, ncols=8, figsize=(20, 2.5))  # Create a 1x8 grid\n\n# Plot the image\naxes[0].imshow(data_to_show[0], cmap='gray')\naxes[0].set_title('Image')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"_uuid":"2cb93293-cb0f-4908-aa40-33feea9ef880","_cell_guid":"42caba78-1715-43e4-b17b-18d8a64100a8","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-14T16:06:50.092863Z","iopub.execute_input":"2024-04-14T16:06:50.093462Z","iopub.status.idle":"2024-04-14T16:06:50.42875Z","shell.execute_reply.started":"2024-04-14T16:06:50.093408Z","shell.execute_reply":"2024-04-14T16:06:50.426171Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/2664565292.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  target = torch.tensor(self.dataframe.iloc[idx][-1], dtype=torch.float32)  # Rings浣涓虹\n/tmp/ipykernel_33/2664565292.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  target = torch.tensor(self.dataframe.iloc[idx][-1], dtype=torch.float32)  # Rings浣涓虹\n/tmp/ipykernel_33/2664565292.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  target = torch.tensor(self.dataframe.iloc[idx][-1], dtype=torch.float32)  # Rings浣涓虹\n/tmp/ipykernel_33/2664565292.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  target = torch.tensor(self.dataframe.iloc[idx][-1], dtype=torch.float32)  # Rings浣涓虹\n","output_type":"stream"},{"name":"stdout","text":"tensor([[1.1621, 1.1621, 1.1621,  ..., 1.1621, 1.1621, 1.1621],\n        [1.1621, 1.1621, 1.1621,  ..., 1.1621, 1.1621, 1.1621],\n        [1.1621, 1.1621, 1.1621,  ..., 1.1621, 1.1621, 1.1621],\n        ...,\n        [1.1621, 1.1621, 1.1621,  ..., 1.1621, 1.1621, 1.1621],\n        [1.1621, 1.1621, 1.1621,  ..., 1.1621, 1.1621, 1.1621],\n        [1.1621, 1.1621, 1.1621,  ..., 1.1621, 1.1621, 1.1621]]) tensor([[-2.0480, -2.0480, -2.0480,  ..., -2.0480, -2.0480, -2.0480],\n        [-2.0480, -2.0480, -2.0480,  ..., -2.0480, -2.0480, -2.0480],\n        [-2.0480, -2.0480, -2.0480,  ..., -2.0480, -2.0480, -2.0480],\n        ...,\n        [-2.0480, -2.0480, -2.0480,  ..., -2.0480, -2.0480, -2.0480],\n        [-2.0480, -2.0480, -2.0480,  ..., -2.0480, -2.0480, -2.0480],\n        [-2.0480, -2.0480, -2.0480,  ..., -2.0480, -2.0480, -2.0480]]) tensor([[-2.0065, -2.0065, -2.0065,  ..., -2.0065, -2.0065, -2.0065],\n        [-2.0065, -2.0065, -2.0065,  ..., -2.0065, -2.0065, -2.0065],\n        [-2.0065, -2.0065, -2.0065,  ..., -2.0065, -2.0065, -2.0065],\n        ...,\n        [-2.0065, -2.0065, -2.0065,  ..., -2.0065, -2.0065, -2.0065],\n        [-2.0065, -2.0065, -2.0065,  ..., -2.0065, -2.0065, -2.0065],\n        [-2.0065, -2.0065, -2.0065,  ..., -2.0065, -2.0065, -2.0065]])\n","output_type":"stream"}]},{"cell_type":"code","source":"def rmsle(y_pred, y_true):\n    \"\"\"\n    Calculate the Root Mean Squared Logarithmic Error (RMSLE).\n\n    Args:\n        y_pred (torch.Tensor): The predicted outputs from the model, should be a tensor.\n        y_true (torch.Tensor): The true target values, should be a tensor of the same shape as y_pred.\n\n    Returns:\n        torch.Tensor: A scalar tensor representing the RMSLE for the current batch.\n    \"\"\"\n    # Ensure predictions and targets are greater than zero after adding one to avoid log(0)\n    log_pred = torch.log1p(y_pred)\n    log_true = torch.log1p(y_true)\n\n    # Calculate the squared differences between the two\n    squared_log_error = (log_pred - log_true) ** 2\n\n    # Mean the squared differences then take the square root\n    mean_squared_log_error = torch.mean(squared_log_error)\n    rmsle = torch.sqrt(mean_squared_log_error)\n\n    return rmsle\n\n# Test it with a simple tensor \ny_pred = torch.tensor([3.0, 5.0, 2.5], dtype=torch.float32)\ny_true = torch.tensor([2.0, 4.0, 3.0], dtype=torch.float32)\n\n# Calculate the RMSLE\nloss = rmsle(y_pred, y_true)\nprint(\"RMSLE Loss:\", loss.item())\n","metadata":{"_uuid":"31b8ca11-b74f-447e-9d0e-dfa6ec12c4f7","_cell_guid":"7b968778-193f-4034-a4d2-f7f8a83d50e9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-14T16:07:24.200705Z","iopub.execute_input":"2024-04-14T16:07:24.201284Z","iopub.status.idle":"2024-04-14T16:07:24.212798Z","shell.execute_reply.started":"2024-04-14T16:07:24.201231Z","shell.execute_reply":"2024-04-14T16:07:24.210912Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"class AbaloneModel(pl.LightningModule):\n    \"\"\"\n    U-Net based regression model for Abalone age prediction.\n    \"\"\"\n\n    def __init__(self):\n        super(AbaloneModel, self).__init__()\n\n        # Encoder-Decoder architecture using U-Net\n        self.model = smp.Unet(\n            encoder_name=\"mit_b1\",  # Select encoder (e.g., ResNet34)\n            # encoder_weights=\"imagenet\",  # Use pretrained weights\n            in_channels=3,\n            classes=1,  # Output a single age prediction\n            decoder_attention_type='scse',  # No activation function or whatever you like\n        )\n\n        # Regressor head to output age prediction\n        self.regressor = nn.Sequential(\n            nn.AdaptiveAvgPool2d(1),  # Pool to 1x1\n            nn.Flatten(),  # Flatten\n            nn.Linear(1, 1),  # Fully connected layer\n        )\n\n    def forward(self, x):\n        # Repeat input channel to match U-Net input (3 channels)\n        x = x.repeat(1, 3, 1, 1)\n\n        # Pass through U-Net encoder-decoder\n        x = self.model(x)\n\n        # Apply regressor head for age prediction\n        x = self.regressor(x)\n\n        return x\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        y_hat = self(x)  # Model output should be [batch_size, 1]\n        y_hat = y_hat.squeeze(-1)  # Remove last dim, shape becomes [batch_size]\n\n        loss = rmsle(y_hat, y)\n\n        # Log training loss\n        self.log(\"train_loss\", loss, on_step=True, on_epoch=False, logger=True, prog_bar=True)\n\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        y_hat = self(x)  # Model predictions on validation set\n        y_hat = y_hat.squeeze(-1)  # Ensure predictions are [batch_size]\n\n        # Calculate loss\n        loss = rmsle(y_hat, y)\n\n        # Optionally: Log validation loss\n        self.log(\"val_loss\", loss, on_step=True, on_epoch=True, logger=True, prog_bar=True)\n\n        # return loss\n\n    def configure_optimizers(self):\n        return torch.optim.SGD(self.parameters(), lr=1e-3)\n","metadata":{"_uuid":"4b89445d-b3d5-45e3-a18d-0ef6cfb63779","_cell_guid":"34fda8f4-6aca-46fe-a1c5-11fca6f055d7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-04-14T16:09:10.175602Z","iopub.execute_input":"2024-04-14T16:09:10.176199Z","iopub.status.idle":"2024-04-14T16:09:10.192364Z","shell.execute_reply.started":"2024-04-14T16:09:10.176156Z","shell.execute_reply":"2024-04-14T16:09:10.19071Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# wandb_logger = WandbLogger(project=\"Abalone\", name=\"Round4\")\n\nmodel = AbaloneModel()\ntrainer = pl.Trainer(max_epochs=40, logger=None)\n\n# Go train that shxt\ntrainer.fit(model, train_loader, val_loader)","metadata":{"_uuid":"4022d328-5b81-49e9-be7f-88bad4c7a420","_cell_guid":"5f2f14b4-c49b-4923-888b-781d923a75d8","collapsed":false,"execution":{"iopub.status.busy":"2024-04-11T03:09:42.712011Z","iopub.execute_input":"2024-04-11T03:09:42.712747Z","iopub.status.idle":"2024-04-11T03:10:25.304009Z","shell.execute_reply.started":"2024-04-11T03:09:42.712699Z","shell.execute_reply":"2024-04-11T03:10:25.302914Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **WTF IT WORKS?**","metadata":{"_uuid":"a04895f1-33cc-4f87-a309-697a1b40dbca","_cell_guid":"5e57f59c-553e-4f5a-9d02-831e5b08ae6a","trusted":true}},{"cell_type":"code","source":"# Ensure the model is in evaluation mode\nmodel.eval()\n\n# Freeze the model to ensure parameters don't change (in PyTorch Lightning)\nmodel.freeze()\n\n# Create a DataFrame to store results\nresults = pd.DataFrame()\n\n# Initialize counters for overall accuracy\naccurate_predictions_count = 0\ntotal_predictions_count = 0\n\n# Disable gradient computation for inference\nwith torch.no_grad():\n    for batch in val_loader:  # Assuming val_loader is your validation set loader\n        inputs, targets = batch\n        # inputs = inputs.to('cuda')  # Move input data to GPU (if using GPU)\n\n        predictions = model(inputs)  # Get model predictions\n        predictions = predictions.squeeze(-1)  # Adjust shape of predictions if needed\n\n        # Convert data to CPU and NumPy\n        predictions = predictions.cpu().numpy()\n        targets = targets.cpu().numpy()\n\n        # Calculate accuracy: predictions within 1 year of actual age\n        accurate_predictions = np.abs(predictions - targets) <= 1\n        accurate_predictions_count += np.sum(accurate_predictions)\n        total_predictions_count += len(predictions)\n\n        # Add results to DataFrame\n        batch_results = pd.DataFrame({\n            \"Predicted Age\": predictions,\n            \"Actual Age\": targets,\n            \"Accurate\": accurate_predictions\n        })\n        results = pd.concat([results, batch_results], ignore_index=True)\n\n# Calculate overall accuracy\noverall_accuracy = accurate_predictions_count / total_predictions_count * 100\nprint(f\"Overall Accuracy: {overall_accuracy:.2f}%\")\n\n# Display or analyze results\nprint(results.head())\n\n# Optionally save results to CSV\nresults.to_csv(\"prediction_results.csv\", index=False)\n","metadata":{"_uuid":"df7cc063-7071-49f1-ab82-ae7d3f47808c","_cell_guid":"49b0f538-b5a1-4539-aeb5-f30609139d01","collapsed":false,"execution":{"iopub.status.busy":"2024-04-10T17:51:39.003104Z","iopub.execute_input":"2024-04-10T17:51:39.003908Z","iopub.status.idle":"2024-04-10T17:51:39.06173Z","shell.execute_reply.started":"2024-04-10T17:51:39.003874Z","shell.execute_reply":"2024-04-10T17:51:39.060809Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}